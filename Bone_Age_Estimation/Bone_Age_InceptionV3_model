import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import pdb
import sys
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "3"   # choose gpu
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
from sklearn.model_selection import train_test_split # function for spliting dataset
from sklearn.metrics import mean_absolute_error as sk_mae
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.allow_growth = True # dont allocate entire vram initially
set_session(tf.Session(config=config))
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from keras.applications.inception_v3 import InceptionV3, preprocess_input
from keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Flatten, Concatenate
from keras.models import Sequential,Model
from keras.metrics import mean_absolute_error
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

# Part1 import data
print("Reading data...")
#pdb.set_trace()   breakpoint for debug
img_bone = "boneage-training-dataset/"     #import image
csv_path = "boneage-training-dataset.csv"  #import csv data
age_bone = pd.read_csv(csv_path)           # read bone age
age_bone['path'] = age_bone['id'].map(lambda x: img_bone+"{}.png".format(x)) #set path
age_bone['exists'] = age_bone['path'].map(os.path.exists)
age_bone['gender'] = age_bone['male'].map(lambda x: "male" if x else "female")#set gender
mu = age_bone['boneage'].mean() #boneage mean
sigma = age_bone['boneage'].std()  #standard deviation
age_bone['zscore'] = age_bone['boneage'].map(lambda x: (x-mu)/sigma)  #z score
age_bone.dropna(inplace=True)
print("{} images found out of total {} images".format(age_bone['exists'].sum(),age_bone.shape[0]))
print("Reading complete !!!\n")

# Part2 Training, Test and validation datasets
print("Preparing training, testing and validation datasets ...")
age_bone['boneage_category'] = pd.cut(age_bone['boneage'], 10)  #split bone age into 10 parts
raw_train_bone, test_bone = train_test_split(age_bone,
                                   test_size = 0.2,
                                   random_state = 2018,
                                   stratify = age_bone['boneage_category']) #test datasets=0.2total train = 0.8total
raw_train_bone, valid_bone = train_test_split(raw_train_bone,
                                   test_size = 0.1,
                                   random_state = 2018,
                                   stratify = raw_train_bone['boneage_category']) # valid = 0.1train
train_bone = raw_train_bone.groupby(['boneage_category', 'male']).apply(lambda x: x.sample(500, replace = True)).reset_index(drop=True) #balance the distribution of male and female
train_size = train_bone.shape[0]
valid_size = valid_bone.shape[0]
test_size = test_bone.shape[0]
print("# Training images:   {}".format(train_size))
print("# Validation images: {}".format(valid_size))
print("# Testing images:    {}".format(test_size))

#Part3 pre img processing
img_size = (224, 224)  #img size
def img_gen(in_bone,path_c,out_c,gender_c,batch_size, **dflow_args):
     img_data_gen = ImageDataGenerator(samplewise_center=False,  #preimage processing generator  average of image = 0
                            samplewise_std_normalization=False,  #input / standard deviation
                            horizontal_flip = True,    # random horizontal flip
                            vertical_flip = False,
                            height_shift_range = 0.15,
                            width_shift_range = 0.15,
                            rotation_range = 5,    #random rotate 5
                            shear_range = 0.01,   # cut anti-clockwise
                            fill_mode = 'reflect', #padding in defined model: abcddcba|abcd|dcbaabcd when pix out of range during the preprocessing
                            zoom_range=0.25,  # Range for random zoom
                           preprocessing_function = preprocess_input)
     base_dir = os.path.dirname(in_bone[path_c].values[0]) #return in_bone[path_c\directory
     bone_gen = img_data_gen.flow_from_directory(base_dir, class_mode = 'sparse', batch_size = batch_size, shuffle=True, **dflow_args)  #Takes the path to a directory & generates batches of augmented data. sparse: 1D integer labels
     bone_gen.filenames = [x.split("/")[1] for x in in_bone[path_c].values]
     bone_gen.classes = np.column_stack([in_bone[out_c].values,in_bone[gender_c].values.astype(float)])
     bone_gen.samples = in_bone.shape[0]
     bone_gen.n = in_bone.shape[0]
     bone_gen._set_index_array()
     for batch in bone_gen:
      yield [batch[0],batch[1][:,1]],batch[1][:,0]

print("Preparing train data...")
train_gen = img_gen(train_bone,
                     path_c = 'path',
                    out_c = 'zscore',
                    gender_c = 'male',
                    batch_size = 10,
                    target_size = img_size,
                    color_mode = 'rgb',
                    seed=8300)  #random number seed to disorganize data
print("Preparing validation data...")
valid_X, valid_Y = next(img_gen(valid_bone,
                                 path_c = 'path',
                                out_c = 'zscore',
                                gender_c = 'male',
                                batch_size = valid_size,
                                target_size = img_size,
                                 color_mode = 'rgb',
                                 seed=8300)) # using a fixed dataset as validation data set 用next是为了增加随机性？？
img_shape = valid_X[0][0,:,:,:].shape
print("Image shape: "+str(img_shape))
print("Data prepared !!!\n")

#Part 3 define model
print("Define model ...")
img = Input(shape = img_shape)
gender = Input(shape=(1,))
cnn_vec = InceptionV3(input_shape = img_shape, weights = 'imagenet', include_top = False)(img)  #using defined inceptionv3 model
cnn_vec = GlobalAveragePooling2D()(cnn_vec) # add a global spatial average pooling layer
cnn_vec = Dropout(0.2)(cnn_vec)     # 20% CNN_VEC data = 0, keep overfit
gender_vec = Dense(32,activation='relu')(gender) #putput size =32 activation function = relu if x>0 x= x else x=0
features = Concatenate(axis=-1)([cnn_vec,gender_vec]) #import same shape vector of table and output vector based on axis = -1
dense_layer = Dense(1024, activation = 'relu')(features) #putput size =1024 activation function = relu if x>0 x= x else x=0
dense_layer = Dropout(0.2)(dense_layer)
dense_layer = Dense(1024,activation='relu')(dense_layer)#putput size =1024 activation function = relu if x>0 x= x else x=0
dense_layer = Dropout(0.2)(dense_layer)
output_layer = Dense(1, activation = 'linear')(dense_layer) # outputlayer
bone_age_model = Model(inputs=[img,gender],outputs=output_layer)

#Part4 Compile model
def img_mae(in_gt, in_pred):
    return mean_absolute_error(mu+sigma*in_gt, mu+sigma*in_pred)
bone_age_model.compile(loss = 'mean_squared_error', optimizer = 'adam',  metrics = [img_mae]) #compile model, loss function = mse, optimzer = adam
bone_age_model.summary() #print
print("Model compiled !!!\n")

#Training deep model
print("Training cnn model ...")
#Model Callbacks
weight_path="bone_age_inceptionv3_gender_50_epochs_relu_less_dropout_dense.best.hdf5" # saved_model_name(path)
checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,save_best_only=True, mode='min', save_weights_only = True) #save model after each train epoch, weight_path = save path, monitor=monitored data verbose=1 : deatail information, save best model(only weight)
reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001) #after training,reduce rate = 0.8, not increase period =10 threshold value of new most optimzed value, change to normal after reduced period =5, min value of learning rate
early = EarlyStopping(monitor="val_loss", mode="min", patience=10) # when monitored data is not improving, stop the trainning  After 10 stopped  min:when monitor value not decrease
callbacks_list = [checkpoint, reduceLROnPlat, early, ]
if not os.path.exists(weight_path):
    bone_age_model.fit_generator( train_gen,                         #generater function
                                  steps_per_epoch = train_size/10,   #  Total number of steps to yield from generator before declaring one epoch finished and starting the next epoch
                                  validation_data = (valid_X,valid_Y),  #validation gengerate function
                                  epochs = 50,
                                  callbacks = callbacks_list,
                                  verbose=1)
bone_age_model.load_weights(weight_path)
print("Training complete !!!\n")


#Part5 evaluating model on test data
print("Evaluating model on test data ...\n")
print("Preparing testing dataset...")
test_X, test_Y = next(img_gen(test_bone,
                             path_c = 'path',
                            out_c = 'zscore',
                            gender_c = 'male',
                            batch_size = test_size,
                            target_size = img_size,
                             color_mode = 'rgb',
                             seed=8300)) # one big batch
print("Data prepared !!!")
pred_Y = mu+sigma*bone_age_model.predict(x=test_X,batch_size=25,verbose=1)  #predict output
test_Y_out = mu+sigma*test_Y
print("Mean absolute error on test data: "+str(sk_mae(test_Y_months,pred_Y)))

fig, ax1 = plt.subplots(1,1, figsize = (6,6))
ax1.plot(test_Y_out, pred_Y, 'r.', label = 'predictions')
ax1.plot(test_Y_out, test_Y_out, 'b-', label = 'actual')
ax1.legend()
ax1.set_xlabel('Actual Age (Months)')
ax1.set_ylabel('Predicted Age (Months)')

ord_idx = np.argsort(test_Y)
ord_idx = ord_idx[np.linspace(0, len(ord_idx)-1, num=8).astype(int)] # take 8 evenly spaced ones
fig, m_axs = plt.subplots(2, 4, figsize = (16, 32))
for (idx, c_ax) in zip(ord_idx, m_axs.flatten()):
    c_ax.imshow(test_X[0][idx, :,:,0], cmap = 'bone')
    title = 'Age: %2.1f\nPredicted Age: %2.1f\nGender: ' % (test_Y_out[idx], pred_Y[idx])
    if test_X[1][idx]==0:
      title+="Female\n"
    else:
      title+="Male\n"
    c_ax.set_title(title)
    c_ax.axis('off')
plt.show()
